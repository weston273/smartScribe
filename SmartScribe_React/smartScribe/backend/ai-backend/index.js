import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import fetch from "node-fetch";

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// âœ… Enable CORS for all origins (or specify your frontend if needed)
app.use(cors({
  origin: "https://smart-scribe-a665-git-master-westons-projects-06d070f3.vercel.app", // or replace with 'https://your-frontend.vercel.app'
  methods: ["GET", "POST", "OPTIONS"],
  allowedHeaders: ["Content-Type", "Authorization"]
}));

app.use(express.json());

// âœ… Load API keys from .env
const apiKeys = process.env.OPENROUTER_KEYS
  ? process.env.OPENROUTER_KEYS.split(",").map(k => k.trim())
  : [];

let currentKeyIndex = 0;

// âœ… Choose model based on task
function getModel(task = "general") {
  switch (task) {
    case "chat":
    case "notes":
      return "mistralai/mistral-7b-instruct";
    case "summarize":
    case "recap":
      return "deepseek/deepseek-r1";
    case "quiz":
    case "video":
      return "deepseek/deepseek-v3-0324:free";
    case "ultralong":
      return "openai/gpt-4o";
    default:
      return "mistralai/mistral-7b-instruct";
  }
}

// âœ… Try all keys with fallback
async function fetchWithFallback(messages, task) {
  const model = getModel(task);

  for (let i = 0; i < apiKeys.length; i++) {
    const key = apiKeys[currentKeyIndex];
    console.log(`ðŸ§  Trying key #${currentKeyIndex + 1} with model: ${model}`);

    try {
      const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
          Authorization: `Bearer ${key}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model,
          messages,
          temperature: 0.7
        })
      });

      if (response.status === 429 || response.status === 401) {
        console.warn(`âš ï¸ Key #${currentKeyIndex + 1} failed (rate limit or unauthorized). Switching...`);
        currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
        continue;
      }

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`âŒ OpenRouter error: ${errorText}`);
      }

      const data = await response.json();
      console.log("âœ… Success:", data);
      return data;

    } catch (err) {
      console.error(`âŒ Key #${currentKeyIndex + 1} error:`, err.message);
      currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
    }
  }

  throw new Error("ðŸš« All API keys failed or exhausted.");
}

// âœ… Main AI endpoint
app.post("/api/chat", async (req, res) => {
  const { messages, task } = req.body;

  if (!messages || !Array.isArray(messages)) {
    return res.status(400).json({ error: "âŒ 'messages' must be an array." });
  }

  try {
    const data = await fetchWithFallback(messages, task);
    res.status(200).json(data);
  } catch (error) {
    console.error("ðŸ”¥ Critical failure:", error.message);
    res.status(500).json({ error: "All keys failed or exhausted." });
  }
});

// âœ… Ping endpoint (optional)
app.get("/", (req, res) => {
  res.send("âœ… SmartScribe AI backend is running.");
});

// âœ… Start server
app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on port ${PORT}`);
});
